# build agent based langchain

## local LLM service

- install ollama: curl -fsSL https://ollama.com/install.sh | sh
- download model: ollama pull llama3.2:3b
- run service: ollama serve
- run LLM: ollama run myllama

  https://docs.ollama.com/quickstart

## other framework

https://docs.agno.com/get-started/quickstart
