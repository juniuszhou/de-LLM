{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1da3bd28",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "messages [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 53, 'total_tokens': 54, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama3.2:3b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-408', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--69d19a19-d2de-4825-be03-45abb45f902e-0', usage_metadata={'input_tokens': 53, 'output_tokens': 1, 'total_tokens': 54, 'input_token_details': {}, 'output_token_details': {}})]\n",
            "[AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 53, 'total_tokens': 54, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama3.2:3b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-408', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--69d19a19-d2de-4825-be03-45abb45f902e-0', usage_metadata={'input_tokens': 53, 'output_tokens': 1, 'total_tokens': 54, 'input_token_details': {}, 'output_token_details': {}})]\n",
            "==================================================\n",
            "content='' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 53, 'total_tokens': 54, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama3.2:3b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-408', 'finish_reason': 'stop', 'logprobs': None} id='lc_run--69d19a19-d2de-4825-be03-45abb45f902e-0' usage_metadata={'input_tokens': 53, 'output_tokens': 1, 'total_tokens': 54, 'input_token_details': {}, 'output_token_details': {}}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from langchain.agents import create_agent\n",
        "from langchain.tools import tool\n",
        "import json\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pprint import pprint\n",
        "from langchain.agents.middleware import wrap_tool_call\n",
        "\n",
        "@wrap_tool_call\n",
        "def handle_tool_errors(request, handler):\n",
        "    \"\"\"Handle tool execution errors with custom messages.\"\"\"\n",
        "    try:\n",
        "        return handler(request)\n",
        "    except Exception as e:\n",
        "        # Return a custom error message to the model\n",
        "        return ToolMessage(\n",
        "            content=f\"Tool error: Please check your input and try again. ({str(e)})\",\n",
        "            tool_call_id=request.tool_call[\"id\"]\n",
        "        )\n",
        "\n",
        "@tool\n",
        "def search(query: str) -> str:\n",
        "    \"\"\"Search for information.\"\"\"\n",
        "    return f\"Results for: {query}\"\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model=\"llama3.2:3b\",\n",
        "    temperature=0,\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key=\"ollama\"\n",
        ")\n",
        "\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get weather for from langchain_openai import ChatOpenAIa given city.\"\"\"\n",
        "    return f\"The capital is {city}!\"\n",
        "\n",
        "agent = create_agent(\n",
        "    model=llm,\n",
        "    tools=[search],\n",
        "    system_prompt=\"You are a helpful assistant\",\n",
        "    middleware=[handle_tool_errors]\n",
        ")\n",
        "\n",
        "result = agent.invoke({\"input\": \"What's the capital of France?\"})\n",
        "\n",
        "result_dict = dict(result)\n",
        "for key, value in result_dict.items():\n",
        "    print(key, value)\n",
        "\n",
        "print(result_dict[\"messages\"])\n",
        "\n",
        "messages = result_dict[\"messages\"]\n",
        "\n",
        "for message in list(messages):\n",
        "    print(\"=\"*50)\n",
        "    print(message)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4c9b67b8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'messages': [HumanMessage(content='what is the weather outside?', additional_kwargs={}, response_metadata={}, id='26282c85-a502-42dd-bf98-df8f8741f301'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 343, 'total_tokens': 357, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama3.2:3b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-472', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--02d9f541-9bc7-4fc5-99d0-44456e962c27-0', tool_calls=[{'name': 'get_user_location', 'args': {}, 'id': 'call_2jbdmtvl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 343, 'output_tokens': 14, 'total_tokens': 357, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='Florida', name='get_user_location', id='323cd70e-e362-46b3-9773-e0f445f4e568', tool_call_id='call_2jbdmtvl'), AIMessage(content='Looks like we\\'re in the Sunshine State! According to my forecast, it\\'s a \"hot\" topic - the current weather in Florida is mostly sunny with a high of 78°F (25°C) and a low of 62°F (17°C). It\\'s a great day to soak up some rays or enjoy the beach. But don\\'t get too \"burned\" by the heat, stay hydrated!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 180, 'total_tokens': 264, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama3.2:3b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-138', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8f6c9278-de37-4a4d-8086-ac65c70b9059-0', usage_metadata={'input_tokens': 180, 'output_tokens': 84, 'total_tokens': 264, 'input_token_details': {}, 'output_token_details': {}})]}\n",
            "[HumanMessage(content='what is the weather outside?', additional_kwargs={}, response_metadata={}, id='26282c85-a502-42dd-bf98-df8f8741f301'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 343, 'total_tokens': 357, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama3.2:3b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-472', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--02d9f541-9bc7-4fc5-99d0-44456e962c27-0', tool_calls=[{'name': 'get_user_location', 'args': {}, 'id': 'call_2jbdmtvl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 343, 'output_tokens': 14, 'total_tokens': 357, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='Florida', name='get_user_location', id='323cd70e-e362-46b3-9773-e0f445f4e568', tool_call_id='call_2jbdmtvl'), AIMessage(content='Looks like we\\'re in the Sunshine State! According to my forecast, it\\'s a \"hot\" topic - the current weather in Florida is mostly sunny with a high of 78°F (25°C) and a low of 62°F (17°C). It\\'s a great day to soak up some rays or enjoy the beach. But don\\'t get too \"burned\" by the heat, stay hydrated!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 180, 'total_tokens': 264, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama3.2:3b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-138', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8f6c9278-de37-4a4d-8086-ac65c70b9059-0', usage_metadata={'input_tokens': 180, 'output_tokens': 84, 'total_tokens': 264, 'input_token_details': {}, 'output_token_details': {}})]\n",
            "[HumanMessage(content='what is the weather outside?', additional_kwargs={}, response_metadata={}, id='26282c85-a502-42dd-bf98-df8f8741f301'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 343, 'total_tokens': 357, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama3.2:3b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-472', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--02d9f541-9bc7-4fc5-99d0-44456e962c27-0', tool_calls=[{'name': 'get_user_location', 'args': {}, 'id': 'call_2jbdmtvl', 'type': 'tool_call'}], usage_metadata={'input_tokens': 343, 'output_tokens': 14, 'total_tokens': 357, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='Florida', name='get_user_location', id='323cd70e-e362-46b3-9773-e0f445f4e568', tool_call_id='call_2jbdmtvl'), AIMessage(content='Looks like we\\'re in the Sunshine State! According to my forecast, it\\'s a \"hot\" topic - the current weather in Florida is mostly sunny with a high of 78°F (25°C) and a low of 62°F (17°C). It\\'s a great day to soak up some rays or enjoy the beach. But don\\'t get too \"burned\" by the heat, stay hydrated!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 84, 'prompt_tokens': 180, 'total_tokens': 264, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama3.2:3b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-138', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--8f6c9278-de37-4a4d-8086-ac65c70b9059-0', usage_metadata={'input_tokens': 180, 'output_tokens': 84, 'total_tokens': 264, 'input_token_details': {}, 'output_token_details': {}}), HumanMessage(content='thank you!', additional_kwargs={}, response_metadata={}, id='560fd684-0b7e-4086-942f-bc06b8310dc9'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 464, 'total_tokens': 478, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama3.2:3b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-727', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--b1d65aff-3c86-4457-aa2b-b31ea5b4e53e-0', tool_calls=[{'name': 'get_user_location', 'args': {}, 'id': 'call_5jnvpquy', 'type': 'tool_call'}], usage_metadata={'input_tokens': 464, 'output_tokens': 14, 'total_tokens': 478, 'input_token_details': {}, 'output_token_details': {}}), ToolMessage(content='Florida', name='get_user_location', id='c176ae3d-1acc-4992-b27a-979adde327b8', tool_call_id='call_5jnvpquy'), AIMessage(content='You\\'re welcome! It\\'s a \"tropical\" treat to help with your weather queries. If you need more forecast info or just want to \"sea\" what the future holds, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 301, 'total_tokens': 344, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'llama3.2:3b', 'system_fingerprint': 'fp_ollama', 'id': 'chatcmpl-617', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--1eb74353-522e-4cf2-a0f8-1d44f4be3dc4-0', usage_metadata={'input_tokens': 301, 'output_tokens': 43, 'total_tokens': 344, 'input_token_details': {}, 'output_token_details': {}})]\n"
          ]
        }
      ],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import create_agent\n",
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.tools import tool, ToolRuntime\n",
        "from langgraph.checkpoint.memory import InMemorySaver\n",
        "from langchain.agents.structured_output import ToolStrategy\n",
        "\n",
        "\n",
        "model = ChatOpenAI(\n",
        "    model=\"llama3.2:3b\",\n",
        "    temperature=0,\n",
        "    base_url=\"http://localhost:11434/v1\",\n",
        "    api_key=\"ollama\"\n",
        ")\n",
        "\n",
        "# Define system prompt\n",
        "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
        "\n",
        "You have access to two tools:\n",
        "\n",
        "- get_weather_for_location: use this to get the weather for a specific location\n",
        "- get_user_location: use this to get the user's location\n",
        "\n",
        "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\"\n",
        "\n",
        "# Define context schema\n",
        "@dataclass\n",
        "class Context:\n",
        "    \"\"\"Custom runtime context schema.\"\"\"\n",
        "    user_id: str\n",
        "\n",
        "# Define tools\n",
        "@tool\n",
        "def get_weather_for_location(city: str) -> str:\n",
        "    \"\"\"Get weather for a given city.\"\"\"\n",
        "    return f\"It's always sunny in {city}!\"\n",
        "\n",
        "@tool\n",
        "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
        "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
        "    user_id = runtime.context.user_id\n",
        "    return \"Florida\" if user_id == \"1\" else \"SF\"\n",
        "\n",
        "# Define response format\n",
        "@dataclass\n",
        "class ResponseFormat:\n",
        "    \"\"\"Response schema for the agent.\"\"\"\n",
        "    # A punny response (always required)\n",
        "    punny_response: str\n",
        "    # Any interesting information about the weather if available\n",
        "    weather_conditions: str | None = None\n",
        "\n",
        "# Set up memory\n",
        "checkpointer = InMemorySaver()\n",
        "\n",
        "# Create agent\n",
        "agent = create_agent(\n",
        "    model=model,\n",
        "    system_prompt=SYSTEM_PROMPT,\n",
        "    tools=[get_user_location, get_weather_for_location],\n",
        "    context_schema=Context,\n",
        "    response_format=ToolStrategy(ResponseFormat),\n",
        "    checkpointer=checkpointer\n",
        ")\n",
        "\n",
        "# Run agent\n",
        "# `thread_id` is a unique identifier for a given conversation.\n",
        "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "response = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
        "    config=config,\n",
        "    context=Context(user_id=\"1\")\n",
        ")\n",
        "\n",
        "print(response)\n",
        "\n",
        "print(response['messages'])\n",
        "# ResponseFormat(\n",
        "#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n",
        "#     weather_conditions=\"It's always sunny in Florida!\"\n",
        "# )\n",
        "\n",
        "\n",
        "# Note that we can continue the conversation using the same `thread_id`.\n",
        "response = agent.invoke(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
        "    config=config,\n",
        "    context=Context(user_id=\"1\")\n",
        ")\n",
        "\n",
        "print(response['messages'])\n",
        "# ResponseFormat(\n",
        "#     punny_response=\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\",\n",
        "#     weather_conditions=None\n",
        "# )"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
