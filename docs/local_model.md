# Local model service for LLM

## ollama

```bash
ollama serve
ollama run llama3.2:3b
ollama ps
ollama stop llama3.2:3b
```
