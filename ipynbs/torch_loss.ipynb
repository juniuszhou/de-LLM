{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f04a89",
   "metadata": {},
   "source": [
    "CROSS ENTROPY LOSS, Negative Log-Likelihood Loss\n",
    "CE = -log(softmax(predicted)[target_class])\n",
    "used in LLM and transformers, it is like a multiple classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396f42a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example - Image Classification (3 classes: cat, dog, bird):\n",
      "  Logits shape: torch.Size([3, 3])\n",
      "  Targets: [2, 0, 1]\n",
      "  Cross Entropy Loss: 2.5156\n",
      "  Probabilities: [[0.6590011715888977, 0.24243298172950745, 0.09856589138507843], [0.10860372334718704, 0.8024790287017822, 0.08891721069812775], [0.05449745059013367, 0.0493113249540329, 0.8961912393569946]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "# Example: Classifying images into 3 classes (cat, dog, bird)\n",
    "# Input: raw logits for 3 classes (no softmax needed!)\n",
    "logits = torch.tensor([[2.0, 1.0, 0.1],    # Predicted: class 0 (cat)\n",
    "                       [0.5, 2.5, 0.3],    # Predicted: class 1 (dog)\n",
    "                       [0.2, 0.1, 3.0]])   # Predicted: class 2 (bird)\n",
    "\n",
    "# small loss example\n",
    "# targets = torch.tensor([0, 1, 2])  # True labels: cat, dog, bird\n",
    "\n",
    "# big loss example\n",
    "targets = torch.tensor([2, 0, 1])  # True labels: cat, dog, bird\n",
    "\n",
    "ce_value = ce_loss(logits, targets)\n",
    "print(f\"Example - Image Classification (3 classes: cat, dog, bird):\")\n",
    "print(f\"  Logits shape: {logits.shape}\")\n",
    "print(f\"  Targets: {targets.tolist()}\")\n",
    "print(f\"  Cross Entropy Loss: {ce_value.item():.4f}\")\n",
    "\n",
    "# Show probabilities after softmax. revert the logits to probabilities\n",
    "probs = F.softmax(logits, dim=1)\n",
    "print(f\"  Probabilities: {probs.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b0e0b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (10) to match target batch_size (3).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# small loss example\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# targets = torch.tensor([0, 1, 2])  # True labels: cat, dog, bird\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# big loss example\u001b[39;00m\n\u001b[32m     10\u001b[39m targets = torch.tensor([\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m]) \n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m loss = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCross Entropy Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/junius/de-LLM/.venv/lib/python3.12/site-packages/torch/nn/functional.py:3458\u001b[39m, in \u001b[36mcross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[39m\n\u001b[32m   3456\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3457\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3459\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3462\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3464\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3465\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: Expected input batch_size (10) to match target batch_size (3)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "logits = torch.rand([3, 10])\n",
    "\n",
    "# small loss example\n",
    "# targets = torch.tensor([0, 1, 2])  # True labels: cat, dog, bird\n",
    "\n",
    "# big loss example\n",
    "targets = torch.tensor([2, 0, 1]) \n",
    "\n",
    "loss = F.cross_entropy(logits, targets)\n",
    "print(f\"Cross Entropy Loss: {loss.item():.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
