{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db35c337",
   "metadata": {},
   "source": [
    "Demo to use some functions in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8116b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "\"softmax_kernel_impl\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m a = torch.randint(\u001b[32m1\u001b[39m, \u001b[32m100\u001b[39m, (\u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m))\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# convert the distribution to a probability distribution, means all items add up to 1\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m norm = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(norm)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/github/junius/de-LLM/.venv/lib/python3.12/site-packages/torch/nn/functional.py:2133\u001b[39m, in \u001b[36msoftmax\u001b[39m\u001b[34m(input, dim, _stacklevel, dtype)\u001b[39m\n\u001b[32m   2131\u001b[39m     dim = _get_softmax_dim(\u001b[33m\"\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m.dim(), _stacklevel)\n\u001b[32m   2132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2133\u001b[39m     ret = \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2135\u001b[39m     ret = \u001b[38;5;28minput\u001b[39m.softmax(dim, dtype=dtype)\n",
      "\u001b[31mNotImplementedError\u001b[39m: \"softmax_kernel_impl\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "a = torch.rand([3, 3, 3])\n",
    "# convert the distribution to a probability distribution, means all items add up to 1\n",
    "norm = F.softmax(a, dim=0)\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a6956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.3570, 0.1253, 2.3570, 0.1332, 0.2340, 1.1473, 0.0561, 1.8408, 0.2787,\n",
      "        0.6315], grad_fn=<PowBackward0>)\n",
      "tensor([3.6644, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,\n",
      "        -0.0000])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'zero_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(b)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(a.grad)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m()\n\u001b[32m      8\u001b[39m a.zero_grad()\n\u001b[32m      9\u001b[39m c = b.sum()\n",
      "\u001b[31mAttributeError\u001b[39m: 'Tensor' object has no attribute 'zero_grad'"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "a = torch.randn(10, requires_grad=True)\n",
    "b = a ** 2\n",
    "b.backward(grad=torch.ones_like(b))\n",
    "a.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
